{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import uproot\n",
    "import pandas\n",
    "from functools import partial\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Dense, Conv2D, Dropout, AlphaDropout, Activation, BatchNormalization, Flatten, \\\n",
    "                                    Concatenate, PReLU, TimeDistributed, LSTM, Masking\n",
    "from keras.callbacks import Callback, ModelCheckpoint, CSVLogger\n",
    "#from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "sys.path.insert(0, \"../../python\")\n",
    "from common import *\n",
    "from DataLoader import DataLoader, read_hdf_lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedDense(Dense):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(MaskedDense, self).__init__(units, **kwargs)\n",
    "        \n",
    "    def call(self, inputs, mask=None):\n",
    "        base_out = super(MaskedDense, self).call(inputs)\n",
    "        if mask is None:\n",
    "            return base_out\n",
    "        zeros = tf.zeros_like(base_out)\n",
    "        return tf.where(mask, base_out, zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafeModelCheckpoint(ModelCheckpoint):\n",
    "    def __init__(self, filepath, **kwargs):\n",
    "        super(SafeModelCheckpoint, self).__init__(filepath, **kwargs)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        read_hdf_lock.acquire()\n",
    "        super(SafeModelCheckpoint, self).on_epoch_end(epoch, logs)\n",
    "        read_hdf_lock.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetSetup:\n",
    "    def __init__(self, activation, activation_shared_axes, dropout_rate, first_layer_size, last_layer_size, decay_factor,\n",
    "                 kernel_regularizer, time_distributed):\n",
    "        self.activation = activation\n",
    "        self.activation_shared_axes = activation_shared_axes\n",
    "        if activation == 'relu' or activation == 'PReLU' or activation == 'tanh':\n",
    "            self.DropoutType = Dropout\n",
    "            self.kernel_init = 'he_uniform'\n",
    "            self.apply_batch_norm = True\n",
    "        elif activation == 'selu':\n",
    "            self.DropoutType = AlphaDropout\n",
    "            self.kernel_init = 'lecun_normal'\n",
    "            self.apply_batch_norm = False\n",
    "        else:\n",
    "            raise RuntimeError('Activation \"{}\" not supported.'.format(activation))\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.first_layer_size = first_layer_size\n",
    "        self.last_layer_size = last_layer_size\n",
    "        self.decay_factor = decay_factor\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "        self.time_distributed = time_distributed\n",
    "    \n",
    "    def RecalcLayerSizes(self, n_input_features, width_factor, compression_factor, consider_dropout = True):\n",
    "        drop_factor = 1 + self.dropout_rate if consider_dropout else 1\n",
    "        self.first_layer_size = int(math.ceil(n_input_features * drop_factor * width_factor))\n",
    "        self.last_layer_size = int(math.ceil(n_input_features * drop_factor * compression_factor))\n",
    "    \n",
    "def add_block_ending(net_setup, name_format, layer):\n",
    "    if net_setup.apply_batch_norm:\n",
    "        norm_layer = BatchNormalization(name=name_format.format('norm'))\n",
    "        if net_setup.time_distributed:\n",
    "            norm_layer = TimeDistributed(norm_layer, name=name_format.format('norm'))\n",
    "        norm_layer = norm_layer(layer)\n",
    "    else:\n",
    "        norm_layer = layer\n",
    "    if net_setup.activation == 'PReLU':\n",
    "        activation_layer = PReLU(shared_axes=net_setup.activation_shared_axes,\n",
    "                                 name=name_format.format('activation'))(norm_layer)\n",
    "    else:\n",
    "        activation_layer = Activation(net_setup.activation, name=name_format.format('activation'))(norm_layer)\n",
    "    if net_setup.dropout_rate > 0:\n",
    "        return net_setup.DropoutType(net_setup.dropout_rate, name=name_format.format('dropout'))(activation_layer)\n",
    "    return activation_layer\n",
    "\n",
    "def dense_block(prev_layer, kernel_size, net_setup, block_name, n):\n",
    "    DenseType = MaskedDense if net_setup.time_distributed else Dense\n",
    "    dense = DenseType(kernel_size, name=\"{}_dense_{}\".format(block_name, n),\n",
    "                      kernel_initializer=net_setup.kernel_init,\n",
    "                      kernel_regularizer=net_setup.kernel_regularizer)\n",
    "    if net_setup.time_distributed:\n",
    "        dense = TimeDistributed(dense, name=\"{}_dense_{}\".format(block_name, n))\n",
    "    dense = dense(prev_layer)\n",
    "    return add_block_ending(net_setup, '{}_{{}}_{}'.format(block_name, n), dense)\n",
    "\n",
    "def reduce_n_features_1d(input_layer, net_setup, block_name):\n",
    "    prev_layer = input_layer\n",
    "    current_size = net_setup.first_layer_size\n",
    "    n = 1\n",
    "    while True:\n",
    "        prev_layer = dense_block(prev_layer, current_size, net_setup, block_name, n)\n",
    "        if current_size == net_setup.last_layer_size: break\n",
    "        current_size = max(net_setup.last_layer_size, int(current_size / net_setup.decay_factor))\n",
    "        n += 1\n",
    "    return prev_layer\n",
    "\n",
    "def dense_block_sequence(input_layer, net_setup, n_layers, block_name):\n",
    "    prev_layer = input_layer\n",
    "    current_size = net_setup.first_layer_size\n",
    "    for n in range(n_layers):\n",
    "        prev_layer = dense_block(prev_layer, current_size, net_setup, block_name, n+1)\n",
    "    return prev_layer\n",
    "\n",
    "def conv_block(prev_layer, filters, kernel_size, net_setup, block_name, n):\n",
    "    conv = Conv2D(filters, kernel_size, name=\"{}_conv_{}\".format(block_name, n),\n",
    "                  kernel_initializer=net_setup.kernel_init)(prev_layer)\n",
    "    return add_block_ending(net_setup, '{}_{{}}_{}'.format(block_name, n), conv)\n",
    "\n",
    "def reduce_n_features_2d(input_layer, net_setup, block_name):\n",
    "    conv_kernel=(1, 1)\n",
    "    prev_layer = input_layer\n",
    "    current_size = net_setup.first_layer_size\n",
    "    n = 1\n",
    "    while True:\n",
    "        prev_layer = conv_block(prev_layer, current_size, conv_kernel, net_setup, block_name, n)\n",
    "        if current_size == net_setup.last_layer_size: break\n",
    "        current_size = max(net_setup.last_layer_size, int(current_size / net_setup.decay_factor))\n",
    "        n += 1\n",
    "    return prev_layer\n",
    "\n",
    "def create_model(net_config):\n",
    "    tau_net_setup = NetSetup('PReLU', None, 0.2, 128, 128, 1.4, None, False)\n",
    "    comp_net_setup = NetSetup('PReLU', [1, 2], 0.2, 1024, 64, 1.6, None, False)\n",
    "    #dense_net_setup = NetSetup('relu', 0, 512, 32, 1.4, keras.regularizers.l1(1e-5))\n",
    "    dense_net_setup = NetSetup('PReLU', None, 0.2, 200, 64, 1.4, None, False)\n",
    "            \n",
    "    input_layers = []\n",
    "    high_level_features = []\n",
    "\n",
    "    if len(net_config.tau_branches) > 0:\n",
    "        input_layer_tau = Input(name=\"input_tau\", shape=(len(net_config.tau_branches),))\n",
    "        input_layers.append(input_layer_tau)\n",
    "        tau_net_setup.RecalcLayerSizes(len(net_config.tau_branches), 2, 1)\n",
    "        processed_tau = reduce_n_features_1d(input_layer_tau, tau_net_setup, 'tau')\n",
    "        #processed_tau = dense_block_sequence(input_layer_tau, tau_net_setup, 4, 'tau')\n",
    "        high_level_features.append(processed_tau)\n",
    "    \n",
    "    for loc in net_config.cell_locations:\n",
    "        reduced_inputs = []\n",
    "        for comp_id in range(len(net_config.comp_names)):\n",
    "            comp_name = net_config.comp_names[comp_id]\n",
    "            n_comp_features = len(input_cell_external_branches) + len(net_config.comp_branches[comp_id])\n",
    "            input_layer_comp = Input(name=\"input_{}_{}\".format(loc, comp_name),\n",
    "                                     shape=(n_cells_eta[loc], n_cells_phi[loc], n_comp_features))\n",
    "            input_layers.append(input_layer_comp)\n",
    "            comp_net_setup.RecalcLayerSizes(n_comp_features, 2, 1)\n",
    "            #input_layer_comp_masked = Masking(name=\"input_{}_{}_masking\".format(loc, comp_name))(input_layer_comp)\n",
    "            #reduced_comp = dense_block_sequence(input_layer_comp_masked, comp_net_setup, 4, \"{}_{}\".format(loc, comp_name))\n",
    "            #reduced_comp = reduce_n_features_1d(input_layer_comp_masked, comp_net_setup, \"{}_{}\".format(loc, comp_name))\n",
    "            reduced_comp = reduce_n_features_2d(input_layer_comp, comp_net_setup, \"{}_{}\".format(loc, comp_name))\n",
    "            reduced_inputs.append(reduced_comp)\n",
    "        \n",
    "        cell_output_size = 64\n",
    "        if len(net_config.comp_names) > 1:\n",
    "            conv_all_start = Concatenate(name=\"{}_cell_concat\".format(loc), axis=3)(reduced_inputs)\n",
    "            comp_net_setup.first_layer_size = conv_all_start.shape.as_list()[3]\n",
    "            comp_net_setup.last_layer_size = 64\n",
    "            prev_layer = reduce_n_features_2d(conv_all_start, comp_net_setup, \"{}_all\".format(loc))\n",
    "        else:\n",
    "            prev_layer = reduced_inputs[0]\n",
    "        window_size = 3\n",
    "        current_size = n_cells_eta[loc]\n",
    "        n = 1\n",
    "        while current_size > 1:\n",
    "            win_size = min(current_size, window_size)\n",
    "            prev_layer = conv_block(prev_layer, cell_output_size, (win_size, win_size), comp_net_setup,\n",
    "                                    \"{}_all_{}x{}\".format(loc, win_size, win_size), n)\n",
    "            n += 1\n",
    "            current_size -= window_size - 1\n",
    "            \n",
    "        cells_flatten = Flatten(name=\"{}_cells_flatten\".format(loc))(prev_layer)\n",
    "        high_level_features.append(cells_flatten)\n",
    "        \n",
    "    if len(high_level_features) > 1:\n",
    "        features_concat = Concatenate(name=\"features_concat\", axis=1)(high_level_features)\n",
    "    else:\n",
    "        features_concat = high_level_features[0]\n",
    "    if net_config.final:\n",
    "        #print(features_concat.get_shape())\n",
    "        #dense_net_setup.RecalcLayerSizes(128, 1, 0.5, False)\n",
    "        #final_dense = reduce_n_features_1d(features_concat, dense_net_setup, 'final')\n",
    "        final_dense = dense_block_sequence(features_concat, dense_net_setup, 4, 'final')\n",
    "        output_layer = Dense(n_outputs, name=\"final_dense_last\",\n",
    "                             kernel_initializer=dense_net_setup.kernel_init)(final_dense)\n",
    "\n",
    "    else:\n",
    "        final_dense = dense_block(features_concat, 1024, dense_net_setup,\n",
    "                                  'tmp_{}'.format(net_config.name), 1)\n",
    "        output_layer = Dense(n_outputs, name=\"tmp_{}_dense_last\".format(net_config.name),\n",
    "                             kernel_initializer=dense_net_setup.kernel_init)(final_dense)\n",
    "    softmax_output = Activation(\"softmax\", name=\"main_output\")(output_layer)\n",
    "    \n",
    "    model = Model(input_layers, softmax_output, name=\"DeepTau2017v2\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model, learning_rate):\n",
    "    opt = keras.optimizers.Adam(lr=learning_rate)\n",
    "    #opt = keras.optimizers.Nadam(lr=learning_rate)\n",
    "    #model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "    metrics = [\n",
    "        \"accuracy\", TauLosses.tau_crossentropy, TauLosses.tau_crossentropy_v2,\n",
    "        TauLosses.Le, TauLosses.Lmu, TauLosses.Ljet,\n",
    "        TauLosses.He, TauLosses.Hmu, TauLosses.Htau, TauLosses.Hjet,\n",
    "        TauLosses.Hcat_e, TauLosses.Hcat_mu, TauLosses.Hcat_jet, TauLosses.Hbin,\n",
    "        TauLosses.Hcat_eInv, TauLosses.Hcat_muInv, TauLosses.Hcat_jetInv,\n",
    "        TauLosses.Fe, TauLosses.Fmu, TauLosses.Fjet,\n",
    "    ]\n",
    "    model.compile(loss=TauLosses.tau_crossentropy_v2, optimizer=opt, metrics=metrics, weighted_metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\konst\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\konst\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_inner_egamma (InputLayer) (None, 11, 11, 86)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_inner_muon (InputLayer)   (None, 11, 11, 64)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_inner_hadrons (InputLayer (None, 11, 11, 38)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_outer_egamma (InputLayer) (None, 11, 11, 86)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_outer_muon (InputLayer)   (None, 11, 11, 64)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_outer_hadrons (InputLayer (None, 11, 11, 38)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_conv_1 (Conv2D)    (None, 11, 11, 207)  18009       input_inner_egamma[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_conv_1 (Conv2D)      (None, 11, 11, 154)  10010       input_inner_muon[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_conv_1 (Conv2D)   (None, 11, 11, 92)   3588        input_inner_hadrons[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_conv_1 (Conv2D)    (None, 11, 11, 207)  18009       input_outer_egamma[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_conv_1 (Conv2D)      (None, 11, 11, 154)  10010       input_outer_muon[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_conv_1 (Conv2D)   (None, 11, 11, 92)   3588        input_outer_hadrons[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_norm_1 (BatchNorma (None, 11, 11, 207)  828         inner_egamma_conv_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_norm_1 (BatchNormali (None, 11, 11, 154)  616         inner_muon_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_norm_1 (BatchNorm (None, 11, 11, 92)   368         inner_hadrons_conv_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_norm_1 (BatchNorma (None, 11, 11, 207)  828         outer_egamma_conv_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_norm_1 (BatchNormali (None, 11, 11, 154)  616         outer_muon_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_norm_1 (BatchNorm (None, 11, 11, 92)   368         outer_hadrons_conv_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_activation_1 (PReL (None, 11, 11, 207)  207         inner_egamma_norm_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_activation_1 (PReLU) (None, 11, 11, 154)  154         inner_muon_norm_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_activation_1 (PRe (None, 11, 11, 92)   92          inner_hadrons_norm_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_activation_1 (PReL (None, 11, 11, 207)  207         outer_egamma_norm_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_activation_1 (PReLU) (None, 11, 11, 154)  154         outer_muon_norm_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_activation_1 (PRe (None, 11, 11, 92)   92          outer_hadrons_norm_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_dropout_1 (Dropout (None, 11, 11, 207)  0           inner_egamma_activation_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_dropout_1 (Dropout)  (None, 11, 11, 154)  0           inner_muon_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_dropout_1 (Dropou (None, 11, 11, 92)   0           inner_hadrons_activation_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_dropout_1 (Dropout (None, 11, 11, 207)  0           outer_egamma_activation_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_dropout_1 (Dropout)  (None, 11, 11, 154)  0           outer_muon_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_dropout_1 (Dropou (None, 11, 11, 92)   0           outer_hadrons_activation_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_conv_2 (Conv2D)    (None, 11, 11, 129)  26832       inner_egamma_dropout_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_conv_2 (Conv2D)      (None, 11, 11, 96)   14880       inner_muon_dropout_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_conv_2 (Conv2D)   (None, 11, 11, 57)   5301        inner_hadrons_dropout_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_conv_2 (Conv2D)    (None, 11, 11, 129)  26832       outer_egamma_dropout_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_conv_2 (Conv2D)      (None, 11, 11, 96)   14880       outer_muon_dropout_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_conv_2 (Conv2D)   (None, 11, 11, 57)   5301        outer_hadrons_dropout_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_norm_2 (BatchNorma (None, 11, 11, 129)  516         inner_egamma_conv_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_norm_2 (BatchNormali (None, 11, 11, 96)   384         inner_muon_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_norm_2 (BatchNorm (None, 11, 11, 57)   228         inner_hadrons_conv_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_norm_2 (BatchNorma (None, 11, 11, 129)  516         outer_egamma_conv_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_norm_2 (BatchNormali (None, 11, 11, 96)   384         outer_muon_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_norm_2 (BatchNorm (None, 11, 11, 57)   228         outer_hadrons_conv_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_activation_2 (PReL (None, 11, 11, 129)  129         inner_egamma_norm_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_activation_2 (PReLU) (None, 11, 11, 96)   96          inner_muon_norm_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_activation_2 (PRe (None, 11, 11, 57)   57          inner_hadrons_norm_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_activation_2 (PReL (None, 11, 11, 129)  129         outer_egamma_norm_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_activation_2 (PReLU) (None, 11, 11, 96)   96          outer_muon_norm_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_activation_2 (PRe (None, 11, 11, 57)   57          outer_hadrons_norm_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_dropout_2 (Dropout (None, 11, 11, 129)  0           inner_egamma_activation_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_dropout_2 (Dropout)  (None, 11, 11, 96)   0           inner_muon_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_dropout_2 (Dropou (None, 11, 11, 57)   0           inner_hadrons_activation_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_dropout_2 (Dropout (None, 11, 11, 129)  0           outer_egamma_activation_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_dropout_2 (Dropout)  (None, 11, 11, 96)   0           outer_muon_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_dropout_2 (Dropou (None, 11, 11, 57)   0           outer_hadrons_activation_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_conv_3 (Conv2D)    (None, 11, 11, 104)  13520       inner_egamma_dropout_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_conv_3 (Conv2D)      (None, 11, 11, 77)   7469        inner_muon_dropout_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_conv_3 (Conv2D)   (None, 11, 11, 46)   2668        inner_hadrons_dropout_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_conv_3 (Conv2D)    (None, 11, 11, 104)  13520       outer_egamma_dropout_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_conv_3 (Conv2D)      (None, 11, 11, 77)   7469        outer_muon_dropout_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_conv_3 (Conv2D)   (None, 11, 11, 46)   2668        outer_hadrons_dropout_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_norm_3 (BatchNorma (None, 11, 11, 104)  416         inner_egamma_conv_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_norm_3 (BatchNormali (None, 11, 11, 77)   308         inner_muon_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_norm_3 (BatchNorm (None, 11, 11, 46)   184         inner_hadrons_conv_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_norm_3 (BatchNorma (None, 11, 11, 104)  416         outer_egamma_conv_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_norm_3 (BatchNormali (None, 11, 11, 77)   308         outer_muon_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_norm_3 (BatchNorm (None, 11, 11, 46)   184         outer_hadrons_conv_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_activation_3 (PReL (None, 11, 11, 104)  104         inner_egamma_norm_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_activation_3 (PReLU) (None, 11, 11, 77)   77          inner_muon_norm_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_activation_3 (PRe (None, 11, 11, 46)   46          inner_hadrons_norm_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_activation_3 (PReL (None, 11, 11, 104)  104         outer_egamma_norm_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_activation_3 (PReLU) (None, 11, 11, 77)   77          outer_muon_norm_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_activation_3 (PRe (None, 11, 11, 46)   46          outer_hadrons_norm_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_dropout_3 (Dropout (None, 11, 11, 104)  0           inner_egamma_activation_3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_dropout_3 (Dropout)  (None, 11, 11, 77)   0           inner_muon_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_dropout_3 (Dropou (None, 11, 11, 46)   0           inner_hadrons_activation_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_dropout_3 (Dropout (None, 11, 11, 104)  0           outer_egamma_activation_3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_dropout_3 (Dropout)  (None, 11, 11, 77)   0           outer_muon_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_dropout_3 (Dropou (None, 11, 11, 46)   0           outer_hadrons_activation_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "inner_cell_concat (Concatenate) (None, 11, 11, 227)  0           inner_egamma_dropout_3[0][0]     \n",
      "                                                                 inner_muon_dropout_3[0][0]       \n",
      "                                                                 inner_hadrons_dropout_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_cell_concat (Concatenate) (None, 11, 11, 227)  0           outer_egamma_dropout_3[0][0]     \n",
      "                                                                 outer_muon_dropout_3[0][0]       \n",
      "                                                                 outer_hadrons_dropout_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_conv_1 (Conv2D)       (None, 11, 11, 227)  51756       inner_cell_concat[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_conv_1 (Conv2D)       (None, 11, 11, 227)  51756       outer_cell_concat[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_norm_1 (BatchNormaliz (None, 11, 11, 227)  908         inner_all_conv_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_norm_1 (BatchNormaliz (None, 11, 11, 227)  908         outer_all_conv_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_activation_1 (PReLU)  (None, 11, 11, 227)  227         inner_all_norm_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_activation_1 (PReLU)  (None, 11, 11, 227)  227         outer_all_norm_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_dropout_1 (Dropout)   (None, 11, 11, 227)  0           inner_all_activation_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_dropout_1 (Dropout)   (None, 11, 11, 227)  0           outer_all_activation_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_conv_2 (Conv2D)       (None, 11, 11, 141)  32148       inner_all_dropout_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_conv_2 (Conv2D)       (None, 11, 11, 141)  32148       outer_all_dropout_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_norm_2 (BatchNormaliz (None, 11, 11, 141)  564         inner_all_conv_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_norm_2 (BatchNormaliz (None, 11, 11, 141)  564         outer_all_conv_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_activation_2 (PReLU)  (None, 11, 11, 141)  141         inner_all_norm_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_activation_2 (PReLU)  (None, 11, 11, 141)  141         outer_all_norm_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_dropout_2 (Dropout)   (None, 11, 11, 141)  0           inner_all_activation_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_dropout_2 (Dropout)   (None, 11, 11, 141)  0           outer_all_activation_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_conv_3 (Conv2D)       (None, 11, 11, 88)   12496       inner_all_dropout_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_conv_3 (Conv2D)       (None, 11, 11, 88)   12496       outer_all_dropout_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_norm_3 (BatchNormaliz (None, 11, 11, 88)   352         inner_all_conv_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_norm_3 (BatchNormaliz (None, 11, 11, 88)   352         outer_all_conv_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_activation_3 (PReLU)  (None, 11, 11, 88)   88          inner_all_norm_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_activation_3 (PReLU)  (None, 11, 11, 88)   88          outer_all_norm_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_dropout_3 (Dropout)   (None, 11, 11, 88)   0           inner_all_activation_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_dropout_3 (Dropout)   (None, 11, 11, 88)   0           outer_all_activation_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_conv_4 (Conv2D)       (None, 11, 11, 64)   5696        inner_all_dropout_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_conv_4 (Conv2D)       (None, 11, 11, 64)   5696        outer_all_dropout_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_norm_4 (BatchNormaliz (None, 11, 11, 64)   256         inner_all_conv_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_norm_4 (BatchNormaliz (None, 11, 11, 64)   256         outer_all_conv_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_activation_4 (PReLU)  (None, 11, 11, 64)   64          inner_all_norm_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_activation_4 (PReLU)  (None, 11, 11, 64)   64          outer_all_norm_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_dropout_4 (Dropout)   (None, 11, 11, 64)   0           inner_all_activation_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_dropout_4 (Dropout)   (None, 11, 11, 64)   0           outer_all_activation_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_conv_1 (Conv2D)   (None, 9, 9, 64)     36928       inner_all_dropout_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_conv_1 (Conv2D)   (None, 9, 9, 64)     36928       outer_all_dropout_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_norm_1 (BatchNorm (None, 9, 9, 64)     256         inner_all_3x3_conv_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_norm_1 (BatchNorm (None, 9, 9, 64)     256         outer_all_3x3_conv_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_activation_1 (PRe (None, 9, 9, 64)     64          inner_all_3x3_norm_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_activation_1 (PRe (None, 9, 9, 64)     64          outer_all_3x3_norm_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_dropout_1 (Dropou (None, 9, 9, 64)     0           inner_all_3x3_activation_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_dropout_1 (Dropou (None, 9, 9, 64)     0           outer_all_3x3_activation_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_conv_2 (Conv2D)   (None, 7, 7, 64)     36928       inner_all_3x3_dropout_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_conv_2 (Conv2D)   (None, 7, 7, 64)     36928       outer_all_3x3_dropout_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_norm_2 (BatchNorm (None, 7, 7, 64)     256         inner_all_3x3_conv_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_norm_2 (BatchNorm (None, 7, 7, 64)     256         outer_all_3x3_conv_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_activation_2 (PRe (None, 7, 7, 64)     64          inner_all_3x3_norm_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_activation_2 (PRe (None, 7, 7, 64)     64          outer_all_3x3_norm_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_dropout_2 (Dropou (None, 7, 7, 64)     0           inner_all_3x3_activation_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_dropout_2 (Dropou (None, 7, 7, 64)     0           outer_all_3x3_activation_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "input_tau (InputLayer)          (None, 47)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_conv_3 (Conv2D)   (None, 5, 5, 64)     36928       inner_all_3x3_dropout_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_conv_3 (Conv2D)   (None, 5, 5, 64)     36928       outer_all_3x3_dropout_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tau_dense_1 (Dense)             (None, 113)          5424        input_tau[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_norm_3 (BatchNorm (None, 5, 5, 64)     256         inner_all_3x3_conv_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_norm_3 (BatchNorm (None, 5, 5, 64)     256         outer_all_3x3_conv_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tau_norm_1 (BatchNormalization) (None, 113)          452         tau_dense_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_activation_3 (PRe (None, 5, 5, 64)     64          inner_all_3x3_norm_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_activation_3 (PRe (None, 5, 5, 64)     64          outer_all_3x3_norm_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tau_activation_1 (PReLU)        (None, 113)          113         tau_norm_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_dropout_3 (Dropou (None, 5, 5, 64)     0           inner_all_3x3_activation_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_dropout_3 (Dropou (None, 5, 5, 64)     0           outer_all_3x3_activation_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tau_dropout_1 (Dropout)         (None, 113)          0           tau_activation_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_conv_4 (Conv2D)   (None, 3, 3, 64)     36928       inner_all_3x3_dropout_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_conv_4 (Conv2D)   (None, 3, 3, 64)     36928       outer_all_3x3_dropout_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tau_dense_2 (Dense)             (None, 80)           9120        tau_dropout_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_norm_4 (BatchNorm (None, 3, 3, 64)     256         inner_all_3x3_conv_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_norm_4 (BatchNorm (None, 3, 3, 64)     256         outer_all_3x3_conv_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tau_norm_2 (BatchNormalization) (None, 80)           320         tau_dense_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_activation_4 (PRe (None, 3, 3, 64)     64          inner_all_3x3_norm_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_activation_4 (PRe (None, 3, 3, 64)     64          outer_all_3x3_norm_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tau_activation_2 (PReLU)        (None, 80)           80          tau_norm_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_dropout_4 (Dropou (None, 3, 3, 64)     0           inner_all_3x3_activation_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_dropout_4 (Dropou (None, 3, 3, 64)     0           outer_all_3x3_activation_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tau_dropout_2 (Dropout)         (None, 80)           0           tau_activation_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_conv_5 (Conv2D)   (None, 1, 1, 64)     36928       inner_all_3x3_dropout_4[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_conv_5 (Conv2D)   (None, 1, 1, 64)     36928       outer_all_3x3_dropout_4[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tau_dense_3 (Dense)             (None, 57)           4617        tau_dropout_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_norm_5 (BatchNorm (None, 1, 1, 64)     256         inner_all_3x3_conv_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_norm_5 (BatchNorm (None, 1, 1, 64)     256         outer_all_3x3_conv_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tau_norm_3 (BatchNormalization) (None, 57)           228         tau_dense_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_activation_5 (PRe (None, 1, 1, 64)     64          inner_all_3x3_norm_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_activation_5 (PRe (None, 1, 1, 64)     64          outer_all_3x3_norm_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tau_activation_3 (PReLU)        (None, 57)           57          tau_norm_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_dropout_5 (Dropou (None, 1, 1, 64)     0           inner_all_3x3_activation_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_dropout_5 (Dropou (None, 1, 1, 64)     0           outer_all_3x3_activation_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tau_dropout_3 (Dropout)         (None, 57)           0           tau_activation_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_cells_flatten (Flatten)   (None, 64)           0           inner_all_3x3_dropout_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_cells_flatten (Flatten)   (None, 64)           0           outer_all_3x3_dropout_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "features_concat (Concatenate)   (None, 185)          0           tau_dropout_3[0][0]              \n",
      "                                                                 inner_cells_flatten[0][0]        \n",
      "                                                                 outer_cells_flatten[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "final_dense_1 (Dense)           (None, 200)          37200       features_concat[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "final_norm_1 (BatchNormalizatio (None, 200)          800         final_dense_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "final_activation_1 (PReLU)      (None, 200)          200         final_norm_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "final_dropout_1 (Dropout)       (None, 200)          0           final_activation_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "final_dense_2 (Dense)           (None, 200)          40200       final_dropout_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "final_norm_2 (BatchNormalizatio (None, 200)          800         final_dense_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "final_activation_2 (PReLU)      (None, 200)          200         final_norm_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "final_dropout_2 (Dropout)       (None, 200)          0           final_activation_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "final_dense_3 (Dense)           (None, 200)          40200       final_dropout_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "final_norm_3 (BatchNormalizatio (None, 200)          800         final_dense_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "final_activation_3 (PReLU)      (None, 200)          200         final_norm_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "final_dropout_3 (Dropout)       (None, 200)          0           final_activation_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "final_dense_4 (Dense)           (None, 200)          40200       final_dropout_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "final_norm_4 (BatchNormalizatio (None, 200)          800         final_dense_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "final_activation_4 (PReLU)      (None, 200)          200         final_norm_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "final_dropout_4 (Dropout)       (None, 200)          0           final_activation_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "final_dense_last (Dense)        (None, 4)            804         final_dropout_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Activation)        (None, 4)            0           final_dense_last[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 979,061\n",
      "Trainable params: 969,753\n",
      "Non-trainable params: 9,308\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "TauLosses.SetSFs(1, 1, 3, 1)\n",
    "model_name = \"DeepTau2017v2p5\"\n",
    "model = create_model(netConf_full)\n",
    "compile_model(model, 1e-3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "969753"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GetNumberOfTrainableParams(model, exclude_prefix = 'tmp'):\n",
    "    count = 0\n",
    "    for w in model.trainable_weights:\n",
    "        if not w.name.startswith(exclude_prefix):\n",
    "            count += K.count_params(w)\n",
    "    return count\n",
    "GetNumberOfTrainableParams(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_file(f_name):\n",
    "    file_objs = [ obj for obj in gc.get_objects() if (\"TextIOWrapper\" in str(type(obj))) and (obj.name == f_name)]\n",
    "    for obj in file_objs:\n",
    "        obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeCheckpoint(Callback):\n",
    "    def __init__(self, time_interval, file_name_prefix):\n",
    "        self.time_interval = time_interval\n",
    "        self.file_name_prefix = file_name_prefix\n",
    "        self.initial_time = time.time()\n",
    "        self.last_check_time = self.initial_time\n",
    "    \n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        if batch % 100 != 0: return\n",
    "        current_time = time.time()\n",
    "        delta_t = current_time - self.last_check_time\n",
    "        if delta_t >= self.time_interval:\n",
    "            abs_delta_t_h = (current_time - self.initial_time) / 60. / 60.\n",
    "            read_hdf_lock.acquire()\n",
    "            self.model.save('{}_b{}_{:.1f}h.h5'.format(self.file_name_prefix, batch, abs_delta_t_h))\n",
    "            read_hdf_lock.release()\n",
    "            self.last_check_time = current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(train_suffix, model_name, data_loader, epoch, n_epochs):\n",
    "\n",
    "    train_name = '%s_%s' % (model_name, train_suffix)\n",
    "    \n",
    "    cb_acc = []\n",
    "    for acc_name in [\"acc\", \"weighted_acc\"]:\n",
    "        cb_acc.append(SafeModelCheckpoint(\"%s_acc.hdf5\" % train_name, monitor=\"val_%s\" % acc_name, save_best_only=True,\n",
    "                                          save_weights_only=False, mode=\"max\", verbose=1))\n",
    "    \n",
    "    losses_names = [ \"loss\" ]\n",
    "    for w_suffix in [ \"\", \"weighted_\" ]:\n",
    "        for l_name in [ \"tau_crossentropy\", \"tau_crossentropy_v2\", \"Le\", \"Lmu\", \"Ljet\", \"He\", \"Hmu\", \"Htau\", \"Hjet\",\n",
    "                        \"Hcat_e\", \"Hcat_mu\", \"Hcat_jet\", \"Hbin\" ]:\n",
    "            losses_names.append(w_suffix + l_name)\n",
    "    cb_losses = []\n",
    "    for loss_name in losses_names:\n",
    "        cb_losses.append(SafeModelCheckpoint(\"%s_%s.hdf5\" % (train_name, loss_name), monitor=\"val_%s\" % loss_name,\n",
    "                                             save_best_only=True, save_weights_only=False, mode=\"min\", verbose=1))\n",
    "\n",
    "    log_name = \"%s.log\" % train_name\n",
    "    if os.path.isfile(log_name):\n",
    "        close_file(log_name)\n",
    "        os.remove(log_name)\n",
    "    csv_log = CSVLogger(log_name, append=True)\n",
    "\n",
    "    time_checkpoint = TimeCheckpoint(8*60*60, '{}_historic'.format(train_name))\n",
    "    #pbar = TQDMNotebookCallback(leave_outer=True, show_outer=True, leave_inner = True)\n",
    "    callbacks = [time_checkpoint, csv_log, *cb_acc, *cb_losses]\n",
    "    fit_hist = model.fit_generator(data_loader.generator(True), validation_data=data_loader.generator(False),\n",
    "                                   steps_per_epoch=data_loader.steps_per_epoch, validation_steps=data_loader.validation_steps,\n",
    "                                   callbacks=callbacks, epochs=n_epochs, initial_epoch=epoch, verbose=1)\n",
    "\n",
    "    model.save(\"%s_final.hdf5\" % train_name)\n",
    "    return fit_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72491602 66391602 6100000\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader('N:/tau-ml/tuples-v2-t3/training/part_*.h5', netConf_full, 500, 10000, validation_size=6100000,\n",
    "                    max_queue_size=40, n_passes=-1, return_grid=True)\n",
    "\n",
    "print(loader.total_size, loader.data_size, loader.validation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\konst\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/4\n",
      "118159/132784 [=========================>....] - ETA: 2:00:54 - loss: 0.2279 - acc: 0.8102 - tau_crossentropy: 0.1677 - tau_crossentropy_v2: 0.2248 - Le: 0.0778 - Lmu: 0.0146 - Ljet: 0.1592 - He: 0.1148 - Hmu: 0.1911 - Htau: 0.0350 - Hjet: 0.1579 - weighted_acc: 0.8125 - weighted_tau_crossentropy: 0.1510 - weighted_tau_crossentropy_v2: 0.2279 - weighted_Le: 0.0888 - weighted_Lmu: 0.0222 - weighted_Ljet: 0.1156 - weighted_He: 0.1331 - weighted_Hmu: 0.2107 - weighted_Htau: 0.0547 - weighted_Hjet: 0.0927"
     ]
    }
   ],
   "source": [
    "fit_hist = run_training('step{}'.format(1), model_name, loader, 0, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\konst\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\konst\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\konst\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "TauLosses.SetSFs(1, 1, 3, 1)\n",
    "model_name = \"DeepTau2017v2p5\"\n",
    "model = LoadModel('DeepTau2017v2p5_step1_loss.hdf5')\n",
    "opt_weights = K.batch_get_value(model.optimizer.weights)\n",
    "compile_model(model, 1e-3)\n",
    "model._make_train_function()\n",
    "model.optimizer.set_weights(opt_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4\n",
      "132784/132784 [==============================] - 69107s 520ms/step - loss: 0.1909 - acc: 0.8798 - tau_crossentropy: 0.1382 - tau_crossentropy_v2: 0.1889 - Le: 0.0650 - Lmu: 0.0104 - Ljet: 0.1319 - He: 0.0941 - Hmu: 0.0869 - Htau: 0.0314 - Hjet: 0.1236 - Hcat_e: 0.0516 - Hcat_mu: 0.0048 - Hcat_jet: 0.1101 - Hbin: 0.0076 - Hcat_eInv: 0.0425 - Hcat_muInv: 0.0821 - Hcat_jetInv: 0.0135 - HbinInv: 0.1398 - weighted_acc: 0.8664 - weighted_tau_crossentropy: 0.1262 - weighted_tau_crossentropy_v2: 0.1909 - weighted_Le: 0.0788 - weighted_Lmu: 0.0175 - weighted_Ljet: 0.0930 - weighted_He: 0.1065 - weighted_Hmu: 0.1400 - weighted_Htau: 0.0468 - weighted_Hjet: 0.0726 - weighted_Hcat_e: 0.0568 - weighted_Hcat_mu: 0.0059 - weighted_Hcat_jet: 0.0637 - weighted_Hbin: 0.0065 - weighted_Hcat_eInv: 0.0497 - weighted_Hcat_muInv: 0.1341 - weighted_Hcat_jetInv: 0.0089 - weighted_HbinInv: 0.1012 - val_loss: 0.1604 - val_acc: 0.9041 - val_tau_crossentropy: 0.1295 - val_tau_crossentropy_v2: 0.1718 - val_Le: 0.0574 - val_Lmu: 0.0059 - val_Ljet: 0.1309 - val_He: 0.0853 - val_Hmu: 0.0431 - val_Htau: 0.0200 - val_Hjet: 0.1375 - val_Hcat_e: 0.0472 - val_Hcat_mu: 0.0032 - val_Hcat_jet: 0.1157 - val_Hbin: 0.0105 - val_Hcat_eInv: 0.0381 - val_Hcat_muInv: 0.0399 - val_Hcat_jetInv: 0.0217 - val_HbinInv: 0.1418 - val_weighted_acc: 0.9017 - val_weighted_tau_crossentropy: 0.1059 - val_weighted_tau_crossentropy_v2: 0.1604 - val_weighted_Le: 0.0625 - val_weighted_Lmu: 0.0079 - val_weighted_Ljet: 0.0884 - val_weighted_He: 0.0908 - val_weighted_Hmu: 0.0605 - val_weighted_Htau: 0.0319 - val_weighted_Hjet: 0.0848 - val_weighted_Hcat_e: 0.0458 - val_weighted_Hcat_mu: 0.0022 - val_weighted_Hcat_jet: 0.0679 - val_weighted_Hbin: 0.0096 - val_weighted_Hcat_eInv: 0.0450 - val_weighted_Hcat_muInv: 0.0583 - val_weighted_Hcat_jetInv: 0.0168 - val_weighted_HbinInv: 0.0940\n",
      "\n",
      "Epoch 00002: val_acc improved from -inf to 0.90405, saving model to DeepTau2017v2p5_step1_acc.hdf5\n",
      "\n",
      "Epoch 00002: val_weighted_acc improved from -inf to 0.90168, saving model to DeepTau2017v2p5_step1_acc.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from inf to 0.16038, saving model to DeepTau2017v2p5_step1_loss.hdf5\n",
      "\n",
      "Epoch 00002: val_tau_crossentropy improved from inf to 0.12948, saving model to DeepTau2017v2p5_step1_tau_crossentropy.hdf5\n",
      "\n",
      "Epoch 00002: val_tau_crossentropy_v2 improved from inf to 0.17175, saving model to DeepTau2017v2p5_step1_tau_crossentropy_v2.hdf5\n",
      "\n",
      "Epoch 00002: val_Le improved from inf to 0.05742, saving model to DeepTau2017v2p5_step1_Le.hdf5\n",
      "\n",
      "Epoch 00002: val_Lmu improved from inf to 0.00589, saving model to DeepTau2017v2p5_step1_Lmu.hdf5\n",
      "\n",
      "Epoch 00002: val_Ljet improved from inf to 0.13091, saving model to DeepTau2017v2p5_step1_Ljet.hdf5\n",
      "\n",
      "Epoch 00002: val_He improved from inf to 0.08534, saving model to DeepTau2017v2p5_step1_He.hdf5\n",
      "\n",
      "Epoch 00002: val_Hmu improved from inf to 0.04308, saving model to DeepTau2017v2p5_step1_Hmu.hdf5\n",
      "\n",
      "Epoch 00002: val_Htau improved from inf to 0.01999, saving model to DeepTau2017v2p5_step1_Htau.hdf5\n",
      "\n",
      "Epoch 00002: val_Hjet improved from inf to 0.13747, saving model to DeepTau2017v2p5_step1_Hjet.hdf5\n",
      "\n",
      "Epoch 00002: val_Hcat_e improved from inf to 0.04723, saving model to DeepTau2017v2p5_step1_Hcat_e.hdf5\n",
      "\n",
      "Epoch 00002: val_Hcat_mu improved from inf to 0.00317, saving model to DeepTau2017v2p5_step1_Hcat_mu.hdf5\n",
      "\n",
      "Epoch 00002: val_Hcat_jet improved from inf to 0.11574, saving model to DeepTau2017v2p5_step1_Hcat_jet.hdf5\n",
      "\n",
      "Epoch 00002: val_Hbin improved from inf to 0.01050, saving model to DeepTau2017v2p5_step1_Hbin.hdf5\n",
      "\n",
      "Epoch 00002: val_weighted_tau_crossentropy improved from inf to 0.10587, saving model to DeepTau2017v2p5_step1_weighted_tau_crossentropy.hdf5\n",
      "\n",
      "Epoch 00002: val_weighted_tau_crossentropy_v2 improved from inf to 0.16038, saving model to DeepTau2017v2p5_step1_weighted_tau_crossentropy_v2.hdf5\n",
      "\n",
      "Epoch 00002: val_weighted_Le improved from inf to 0.06248, saving model to DeepTau2017v2p5_step1_weighted_Le.hdf5\n",
      "\n",
      "Epoch 00002: val_weighted_Lmu improved from inf to 0.00793, saving model to DeepTau2017v2p5_step1_weighted_Lmu.hdf5\n",
      "\n",
      "Epoch 00002: val_weighted_Ljet improved from inf to 0.08840, saving model to DeepTau2017v2p5_step1_weighted_Ljet.hdf5\n",
      "\n",
      "Epoch 00002: val_weighted_He improved from inf to 0.09076, saving model to DeepTau2017v2p5_step1_weighted_He.hdf5\n",
      "\n",
      "Epoch 00002: val_weighted_Hmu improved from inf to 0.06052, saving model to DeepTau2017v2p5_step1_weighted_Hmu.hdf5\n",
      "\n",
      "Epoch 00002: val_weighted_Htau improved from inf to 0.03191, saving model to DeepTau2017v2p5_step1_weighted_Htau.hdf5\n",
      "\n",
      "Epoch 00002: val_weighted_Hjet improved from inf to 0.08477, saving model to DeepTau2017v2p5_step1_weighted_Hjet.hdf5\n",
      "\n",
      "Epoch 00002: val_weighted_Hcat_e improved from inf to 0.04578, saving model to DeepTau2017v2p5_step1_weighted_Hcat_e.hdf5\n",
      "\n",
      "Epoch 00002: val_weighted_Hcat_mu improved from inf to 0.00219, saving model to DeepTau2017v2p5_step1_weighted_Hcat_mu.hdf5\n",
      "\n",
      "Epoch 00002: val_weighted_Hcat_jet improved from inf to 0.06793, saving model to DeepTau2017v2p5_step1_weighted_Hcat_jet.hdf5\n",
      "\n",
      "Epoch 00002: val_weighted_Hbin improved from inf to 0.00964, saving model to DeepTau2017v2p5_step1_weighted_Hbin.hdf5\n",
      "Epoch 3/4\n",
      "  1134/132784 [..............................] - ETA: 18:22:26 - loss: 0.1703 - acc: 0.8787 - tau_crossentropy: 0.1295 - tau_crossentropy_v2: 0.1749 - Le: 0.0630 - Lmu: 0.0085 - Ljet: 0.1227 - He: 0.1363 - Hmu: 0.0458 - Htau: 0.0262 - Hjet: 0.1198 - Hcat_e: 0.0514 - Hcat_mu: 0.0041 - Hcat_jet: 0.1037 - Hbin: 0.0082 - Hcat_eInv: 0.0849 - Hcat_muInv: 0.0418 - Hcat_jetInv: 0.0161 - HbinInv: 0.1346 - weighted_acc: 0.8682 - weighted_tau_crossentropy: 0.1075 - weighted_tau_crossentropy_v2: 0.1703 - weighted_Le: 0.0680 - weighted_Lmu: 0.0112 - weighted_Ljet: 0.0821 - weighted_He: 0.1490 - weighted_Hmu: 0.0625 - weighted_Htau: 0.0432 - weighted_Hjet: 0.0632 - weighted_Hcat_e: 0.0495 - weighted_Hcat_mu: 0.0031 - weighted_Hcat_jet: 0.0523 - weighted_Hbin: 0.0070 - weighted_Hcat_eInv: 0.0995 - weighted_Hcat_muInv: 0.0594 - weighted_Hcat_jetInv: 0.0109 - weighted_HbinInv: 0.0844"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-0bff70cf0d95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfit_hist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'step{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-8291e781afd1>\u001b[0m in \u001b[0;36mrun_training\u001b[1;34m(train_suffix, model_name, data_loader, epoch, n_epochs)\u001b[0m\n\u001b[0;32m     29\u001b[0m     fit_hist = model.fit_generator(data_loader.generator(True), validation_data=data_loader.generator(False),\n\u001b[0;32m     30\u001b[0m                                    \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                                    callbacks=callbacks, epochs=n_epochs, initial_epoch=epoch, verbose=1)\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s_final.hdf5\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtrain_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fit_hist = run_training('step{}'.format(1), model_name, loader, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\konst\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\konst\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\konst\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "TauLosses.SetSFs(1, 3, 5, 1)\n",
    "model_name = \"DeepTau2017v2p5\"\n",
    "model = LoadModel('DeepTau2017v2p5_step1_epoch1_loss.hdf5')\n",
    "opt_weights = K.batch_get_value(model.optimizer.weights)\n",
    "compile_model(model, 1e-3)\n",
    "model._make_train_function()\n",
    "model.optimizer.set_weights(opt_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4\n",
      "132784/132784 [==============================] - 69336s 522ms/step - loss: 0.2991 - acc: 0.8002 - tau_crossentropy: 0.0864 - tau_crossentropy_v2: 0.2995 - Le: 0.0616 - Lmu: 0.0182 - Ljet: 0.0998 - He: 0.2664 - Hmu: 0.0248 - Htau: 0.0681 - Hjet: 0.2023 - Hcat_e: 0.0289 - Hcat_mu: 0.0016 - Hcat_jet: 0.0620 - Hbin: 0.0600 - Hcat_eInv: 0.2376 - Hcat_muInv: 0.0232 - Hcat_jetInv: 0.1403 - Fe: 0.0034 - Fmu: 5.5431e-04 - Fjet: 0.0058 - weighted_acc: 0.7881 - weighted_tau_crossentropy: 0.1028 - weighted_tau_crossentropy_v2: 0.2991 - weighted_Le: 0.0815 - weighted_Lmu: 0.0309 - weighted_Ljet: 0.0826 - weighted_He: 0.2743 - weighted_Hmu: 0.0460 - weighted_Htau: 0.0876 - weighted_Hjet: 0.1547 - weighted_Hcat_e: 0.0313 - weighted_Hcat_mu: 0.0018 - weighted_Hcat_jet: 0.0371 - weighted_Hbin: 0.0444 - weighted_Hcat_eInv: 0.2430 - weighted_Hcat_muInv: 0.0442 - weighted_Hcat_jetInv: 0.1176 - weighted_Fe: 0.0042 - weighted_Fmu: 4.0140e-04 - weighted_Fjet: 0.0034 - val_loss: 0.2386 - val_acc: 0.7567 - val_tau_crossentropy: 0.0726 - val_tau_crossentropy_v2: 0.2637 - val_Le: 0.0501 - val_Lmu: 0.0123 - val_Ljet: 0.0945 - val_He: 0.2745 - val_Hmu: 0.0134 - val_Htau: 0.0477 - val_Hjet: 0.2231 - val_Hcat_e: 0.0263 - val_Hcat_mu: 0.0015 - val_Hcat_jet: 0.0706 - val_Hbin: 0.0628 - val_Hcat_eInv: 0.2482 - val_Hcat_muInv: 0.0120 - val_Hcat_jetInv: 0.1526 - val_Fe: 0.0030 - val_Fmu: 6.0786e-04 - val_Fjet: 0.0058 - val_weighted_acc: 0.7592 - val_weighted_tau_crossentropy: 0.0795 - val_weighted_tau_crossentropy_v2: 0.2386 - val_weighted_Le: 0.0629 - val_weighted_Lmu: 0.0203 - val_weighted_Ljet: 0.0750 - val_weighted_He: 0.2644 - val_weighted_Hmu: 0.0231 - val_weighted_Htau: 0.0618 - val_weighted_Hjet: 0.1718 - val_weighted_Hcat_e: 0.0255 - val_weighted_Hcat_mu: 0.0011 - val_weighted_Hcat_jet: 0.0466 - val_weighted_Hbin: 0.0442 - val_weighted_Hcat_eInv: 0.2389 - val_weighted_Hcat_muInv: 0.0220 - val_weighted_Hcat_jetInv: 0.1252 - val_weighted_Fe: 0.0032 - val_weighted_Fmu: 2.6754e-04 - val_weighted_Fjet: 0.0026\n",
      "\n",
      "Epoch 00003: val_acc improved from -inf to 0.75674, saving model to DeepTau2017v2p5_step1_acc.hdf5\n",
      "\n",
      "Epoch 00003: val_weighted_acc improved from -inf to 0.75921, saving model to DeepTau2017v2p5_step1_acc.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from inf to 0.23858, saving model to DeepTau2017v2p5_step1_loss.hdf5\n",
      "\n",
      "Epoch 00003: val_tau_crossentropy improved from inf to 0.07257, saving model to DeepTau2017v2p5_step1_tau_crossentropy.hdf5\n",
      "\n",
      "Epoch 00003: val_tau_crossentropy_v2 improved from inf to 0.26368, saving model to DeepTau2017v2p5_step1_tau_crossentropy_v2.hdf5\n",
      "\n",
      "Epoch 00003: val_Le improved from inf to 0.05008, saving model to DeepTau2017v2p5_step1_Le.hdf5\n",
      "\n",
      "Epoch 00003: val_Lmu improved from inf to 0.01227, saving model to DeepTau2017v2p5_step1_Lmu.hdf5\n",
      "\n",
      "Epoch 00003: val_Ljet improved from inf to 0.09453, saving model to DeepTau2017v2p5_step1_Ljet.hdf5\n",
      "\n",
      "Epoch 00003: val_He improved from inf to 0.27448, saving model to DeepTau2017v2p5_step1_He.hdf5\n",
      "\n",
      "Epoch 00003: val_Hmu improved from inf to 0.01345, saving model to DeepTau2017v2p5_step1_Hmu.hdf5\n",
      "\n",
      "Epoch 00003: val_Htau improved from inf to 0.04773, saving model to DeepTau2017v2p5_step1_Htau.hdf5\n",
      "\n",
      "Epoch 00003: val_Hjet improved from inf to 0.22314, saving model to DeepTau2017v2p5_step1_Hjet.hdf5\n",
      "\n",
      "Epoch 00003: val_Hcat_e improved from inf to 0.02627, saving model to DeepTau2017v2p5_step1_Hcat_e.hdf5\n",
      "\n",
      "Epoch 00003: val_Hcat_mu improved from inf to 0.00148, saving model to DeepTau2017v2p5_step1_Hcat_mu.hdf5\n",
      "\n",
      "Epoch 00003: val_Hcat_jet improved from inf to 0.07057, saving model to DeepTau2017v2p5_step1_Hcat_jet.hdf5\n",
      "\n",
      "Epoch 00003: val_Hbin improved from inf to 0.06283, saving model to DeepTau2017v2p5_step1_Hbin.hdf5\n",
      "\n",
      "Epoch 00003: val_weighted_tau_crossentropy improved from inf to 0.07946, saving model to DeepTau2017v2p5_step1_weighted_tau_crossentropy.hdf5\n",
      "\n",
      "Epoch 00003: val_weighted_tau_crossentropy_v2 improved from inf to 0.23858, saving model to DeepTau2017v2p5_step1_weighted_tau_crossentropy_v2.hdf5\n",
      "\n",
      "Epoch 00003: val_weighted_Le improved from inf to 0.06285, saving model to DeepTau2017v2p5_step1_weighted_Le.hdf5\n",
      "\n",
      "Epoch 00003: val_weighted_Lmu improved from inf to 0.02027, saving model to DeepTau2017v2p5_step1_weighted_Lmu.hdf5\n",
      "\n",
      "Epoch 00003: val_weighted_Ljet improved from inf to 0.07497, saving model to DeepTau2017v2p5_step1_weighted_Ljet.hdf5\n",
      "\n",
      "Epoch 00003: val_weighted_He improved from inf to 0.26441, saving model to DeepTau2017v2p5_step1_weighted_He.hdf5\n",
      "\n",
      "Epoch 00003: val_weighted_Hmu improved from inf to 0.02306, saving model to DeepTau2017v2p5_step1_weighted_Hmu.hdf5\n",
      "\n",
      "Epoch 00003: val_weighted_Htau improved from inf to 0.06179, saving model to DeepTau2017v2p5_step1_weighted_Htau.hdf5\n",
      "\n",
      "Epoch 00003: val_weighted_Hjet improved from inf to 0.17182, saving model to DeepTau2017v2p5_step1_weighted_Hjet.hdf5\n",
      "\n",
      "Epoch 00003: val_weighted_Hcat_e improved from inf to 0.02546, saving model to DeepTau2017v2p5_step1_weighted_Hcat_e.hdf5\n",
      "\n",
      "Epoch 00003: val_weighted_Hcat_mu improved from inf to 0.00108, saving model to DeepTau2017v2p5_step1_weighted_Hcat_mu.hdf5\n",
      "\n",
      "Epoch 00003: val_weighted_Hcat_jet improved from inf to 0.04660, saving model to DeepTau2017v2p5_step1_weighted_Hcat_jet.hdf5\n",
      "\n",
      "Epoch 00003: val_weighted_Hbin improved from inf to 0.04421, saving model to DeepTau2017v2p5_step1_weighted_Hbin.hdf5\n",
      "Epoch 4/4\n",
      "132784/132784 [==============================] - 69299s 522ms/step - loss: 0.2870 - acc: 0.8405 - tau_crossentropy: 0.0849 - tau_crossentropy_v2: 0.2883 - Le: 0.0595 - Lmu: 0.0185 - Ljet: 0.0974 - He: 0.2139 - Hmu: 0.0321 - Htau: 0.0666 - Hjet: 0.2129 - Hcat_e: 0.0275 - Hcat_mu: 0.0016 - Hcat_jet: 0.0603 - Hbin: 0.0574 - Hcat_eInv: 0.1864 - Hcat_muInv: 0.0306 - Hcat_jetInv: 0.1526 - Fe: 0.0031 - Fmu: 4.5519e-04 - Fjet: 0.0056 - weighted_acc: 0.8284 - weighted_tau_crossentropy: 0.0999 - weighted_tau_crossentropy_v2: 0.2870 - weighted_Le: 0.0783 - weighted_Lmu: 0.0305 - weighted_Ljet: 0.0798 - weighted_He: 0.2126 - weighted_Hmu: 0.0591 - weighted_Htau: 0.0843 - weighted_Hjet: 0.1613 - weighted_Hcat_e: 0.0304 - weighted_Hcat_mu: 0.0018 - weighted_Hcat_jet: 0.0361 - weighted_Hbin: 0.0427 - weighted_Hcat_eInv: 0.1822 - weighted_Hcat_muInv: 0.0573 - weighted_Hcat_jetInv: 0.1252 - weighted_Fe: 0.0040 - weighted_Fmu: 3.4860e-04 - weighted_Fjet: 0.0033 - val_loss: 0.2343 - val_acc: 0.9202 - val_tau_crossentropy: 0.0720 - val_tau_crossentropy_v2: 0.2542 - val_Le: 0.0470 - val_Lmu: 0.0129 - val_Ljet: 0.0942 - val_He: 0.1268 - val_Hmu: 0.0329 - val_Htau: 0.0481 - val_Hjet: 0.2461 - val_Hcat_e: 0.0256 - val_Hcat_mu: 0.0014 - val_Hcat_jet: 0.0767 - val_Hbin: 0.0603 - val_Hcat_eInv: 0.1012 - val_Hcat_muInv: 0.0314 - val_Hcat_jetInv: 0.1695 - val_Fe: 0.0025 - val_Fmu: 4.3256e-04 - val_Fjet: 0.0055 - val_weighted_acc: 0.9156 - val_weighted_tau_crossentropy: 0.0791 - val_weighted_tau_crossentropy_v2: 0.2343 - val_weighted_Le: 0.0606 - val_weighted_Lmu: 0.0207 - val_weighted_Ljet: 0.0751 - val_weighted_He: 0.1167 - val_weighted_Hmu: 0.0541 - val_weighted_Htau: 0.0610 - val_weighted_Hjet: 0.1908 - val_weighted_Hcat_e: 0.0251 - val_weighted_Hcat_mu: 0.0012 - val_weighted_Hcat_jet: 0.0559 - val_weighted_Hbin: 0.0437 - val_weighted_Hcat_eInv: 0.0916 - val_weighted_Hcat_muInv: 0.0529 - val_weighted_Hcat_jetInv: 0.1349 - val_weighted_Fe: 0.0028 - val_weighted_Fmu: 2.0870e-04 - val_weighted_Fjet: 0.0028\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.75674 to 0.92017, saving model to DeepTau2017v2p5_step1_acc.hdf5\n",
      "\n",
      "Epoch 00004: val_weighted_acc improved from 0.75921 to 0.91564, saving model to DeepTau2017v2p5_step1_acc.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.23858 to 0.23430, saving model to DeepTau2017v2p5_step1_loss.hdf5\n",
      "\n",
      "Epoch 00004: val_tau_crossentropy improved from 0.07257 to 0.07196, saving model to DeepTau2017v2p5_step1_tau_crossentropy.hdf5\n",
      "\n",
      "Epoch 00004: val_tau_crossentropy_v2 improved from 0.26368 to 0.25416, saving model to DeepTau2017v2p5_step1_tau_crossentropy_v2.hdf5\n",
      "\n",
      "Epoch 00004: val_Le improved from 0.05008 to 0.04703, saving model to DeepTau2017v2p5_step1_Le.hdf5\n",
      "\n",
      "Epoch 00004: val_Lmu did not improve from 0.01227\n",
      "\n",
      "Epoch 00004: val_Ljet improved from 0.09453 to 0.09416, saving model to DeepTau2017v2p5_step1_Ljet.hdf5\n",
      "\n",
      "Epoch 00004: val_He improved from 0.27448 to 0.12683, saving model to DeepTau2017v2p5_step1_He.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_Hmu did not improve from 0.01345\n",
      "\n",
      "Epoch 00004: val_Htau did not improve from 0.04773\n",
      "\n",
      "Epoch 00004: val_Hjet did not improve from 0.22314\n",
      "\n",
      "Epoch 00004: val_Hcat_e improved from 0.02627 to 0.02564, saving model to DeepTau2017v2p5_step1_Hcat_e.hdf5\n",
      "\n",
      "Epoch 00004: val_Hcat_mu improved from 0.00148 to 0.00144, saving model to DeepTau2017v2p5_step1_Hcat_mu.hdf5\n",
      "\n",
      "Epoch 00004: val_Hcat_jet did not improve from 0.07057\n",
      "\n",
      "Epoch 00004: val_Hbin improved from 0.06283 to 0.06029, saving model to DeepTau2017v2p5_step1_Hbin.hdf5\n",
      "\n",
      "Epoch 00004: val_weighted_tau_crossentropy improved from 0.07946 to 0.07915, saving model to DeepTau2017v2p5_step1_weighted_tau_crossentropy.hdf5\n",
      "\n",
      "Epoch 00004: val_weighted_tau_crossentropy_v2 improved from 0.23858 to 0.23430, saving model to DeepTau2017v2p5_step1_weighted_tau_crossentropy_v2.hdf5\n",
      "\n",
      "Epoch 00004: val_weighted_Le improved from 0.06285 to 0.06059, saving model to DeepTau2017v2p5_step1_weighted_Le.hdf5\n",
      "\n",
      "Epoch 00004: val_weighted_Lmu did not improve from 0.02027\n",
      "\n",
      "Epoch 00004: val_weighted_Ljet did not improve from 0.07497\n",
      "\n",
      "Epoch 00004: val_weighted_He improved from 0.26441 to 0.11668, saving model to DeepTau2017v2p5_step1_weighted_He.hdf5\n",
      "\n",
      "Epoch 00004: val_weighted_Hmu did not improve from 0.02306\n",
      "\n",
      "Epoch 00004: val_weighted_Htau improved from 0.06179 to 0.06105, saving model to DeepTau2017v2p5_step1_weighted_Htau.hdf5\n",
      "\n",
      "Epoch 00004: val_weighted_Hjet did not improve from 0.17182\n",
      "\n",
      "Epoch 00004: val_weighted_Hcat_e improved from 0.02546 to 0.02513, saving model to DeepTau2017v2p5_step1_weighted_Hcat_e.hdf5\n",
      "\n",
      "Epoch 00004: val_weighted_Hcat_mu did not improve from 0.00108\n",
      "\n",
      "Epoch 00004: val_weighted_Hcat_jet did not improve from 0.04660\n",
      "\n",
      "Epoch 00004: val_weighted_Hbin improved from 0.04421 to 0.04373, saving model to DeepTau2017v2p5_step1_weighted_Hbin.hdf5\n"
     ]
    }
   ],
   "source": [
    "fit_hist = run_training('step{}'.format(1), model_name, loader, 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
