{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Conv2D, Dropout, AlphaDropout, Activation, BatchNormalization, Flatten, \\\n",
    "                                    Concatenate, PReLU, TimeDistributed, LSTM, Masking\n",
    "from keras.callbacks import Callback, ModelCheckpoint, CSVLogger\n",
    "#from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "sys.path.insert(0, \"../../python\")\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedDense(Dense):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(MaskedDense, self).__init__(units, **kwargs)\n",
    "        \n",
    "    def call(self, inputs, mask=None):\n",
    "        base_out = super(MaskedDense, self).call(inputs)\n",
    "        if mask is None:\n",
    "            return base_out\n",
    "        zeros = tf.zeros_like(base_out)\n",
    "        return tf.where(mask, base_out, zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetSetup:\n",
    "    def __init__(self, activation, activation_shared_axes, dropout_rate, first_layer_size, last_layer_size, decay_factor,\n",
    "                 kernel_regularizer, time_distributed):\n",
    "        self.activation = activation\n",
    "        self.activation_shared_axes = activation_shared_axes\n",
    "        if activation == 'relu' or activation == 'PReLU' or activation == 'tanh':\n",
    "            self.DropoutType = Dropout\n",
    "            self.kernel_init = 'he_uniform'\n",
    "            self.apply_batch_norm = True\n",
    "        elif activation == 'selu':\n",
    "            self.DropoutType = AlphaDropout\n",
    "            self.kernel_init = 'lecun_normal'\n",
    "            self.apply_batch_norm = False\n",
    "        else:\n",
    "            raise RuntimeError('Activation \"{}\" not supported.'.format(activation))\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.first_layer_size = first_layer_size\n",
    "        self.last_layer_size = last_layer_size\n",
    "        self.decay_factor = decay_factor\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "        self.time_distributed = time_distributed\n",
    "    \n",
    "    def RecalcLayerSizes(self, n_input_features, width_factor, compression_factor, consider_dropout = True):\n",
    "        drop_factor = 1 + self.dropout_rate if consider_dropout else 1\n",
    "        self.first_layer_size = int(math.ceil(n_input_features * drop_factor * width_factor))\n",
    "        self.last_layer_size = int(math.ceil(n_input_features * drop_factor * compression_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_block_ending(net_setup, name_format, layer):\n",
    "    if net_setup.apply_batch_norm:\n",
    "        norm_layer = BatchNormalization(name=name_format.format('norm'))\n",
    "        if net_setup.time_distributed:\n",
    "            norm_layer = TimeDistributed(norm_layer, name=name_format.format('norm'))\n",
    "        norm_layer = norm_layer(layer)\n",
    "    else:\n",
    "        norm_layer = layer\n",
    "    if net_setup.activation == 'PReLU':\n",
    "        activation_layer = PReLU(shared_axes=net_setup.activation_shared_axes,\n",
    "                                 name=name_format.format('activation'))(norm_layer)\n",
    "    else:\n",
    "        activation_layer = Activation(net_setup.activation, name=name_format.format('activation'))(norm_layer)\n",
    "    if net_setup.dropout_rate > 0:\n",
    "        return net_setup.DropoutType(net_setup.dropout_rate, name=name_format.format('dropout'))(activation_layer)\n",
    "    return activation_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_block(prev_layer, kernel_size, net_setup, block_name, n):\n",
    "    DenseType = MaskedDense if net_setup.time_distributed else Dense\n",
    "    dense = DenseType(kernel_size, name=\"{}_dense_{}\".format(block_name, n),\n",
    "                      kernel_initializer=net_setup.kernel_init,\n",
    "                      kernel_regularizer=net_setup.kernel_regularizer)\n",
    "    if net_setup.time_distributed:\n",
    "        dense = TimeDistributed(dense, name=\"{}_dense_{}\".format(block_name, n))\n",
    "    dense = dense(prev_layer)\n",
    "    return add_block_ending(net_setup, '{}_{{}}_{}'.format(block_name, n), dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_n_features_1d(input_layer, net_setup, block_name):\n",
    "    prev_layer = input_layer\n",
    "    current_size = net_setup.first_layer_size\n",
    "    n = 1\n",
    "    while True:\n",
    "        prev_layer = dense_block(prev_layer, current_size, net_setup, block_name, n)\n",
    "        if current_size == net_setup.last_layer_size: break\n",
    "        current_size = max(net_setup.last_layer_size, int(current_size / net_setup.decay_factor))\n",
    "        n += 1\n",
    "    return prev_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_block_sequence(input_layer, net_setup, n_layers, block_name):\n",
    "    prev_layer = input_layer\n",
    "    current_size = net_setup.first_layer_size\n",
    "    for n in range(n_layers):\n",
    "        prev_layer = dense_block(prev_layer, current_size, net_setup, block_name, n+1)\n",
    "    return prev_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(prev_layer, filters, kernel_size, net_setup, block_name, n):\n",
    "    conv = Conv2D(filters, kernel_size, name=\"{}_conv_{}\".format(block_name, n),\n",
    "                  kernel_initializer=net_setup.kernel_init)(prev_layer)\n",
    "    return add_block_ending(net_setup, '{}_{{}}_{}'.format(block_name, n), conv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_n_features_2d(input_layer, net_setup, block_name):\n",
    "    conv_kernel=(1, 1)\n",
    "    prev_layer = input_layer\n",
    "    current_size = net_setup.first_layer_size\n",
    "    n = 1\n",
    "    while True:\n",
    "        prev_layer = conv_block(prev_layer, current_size, conv_kernel, net_setup, block_name, n)\n",
    "        if current_size == net_setup.last_layer_size: break\n",
    "        current_size = max(net_setup.last_layer_size, int(current_size / net_setup.decay_factor))\n",
    "        n += 1\n",
    "    return prev_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cell_model(net_config, loc):\n",
    "    comp_net_setup = NetSetup('PReLU', [1, 2], 0.2, 1024, 64, 1.6, None, False)\n",
    "            \n",
    "    input_layers = []\n",
    "    high_level_features = []\n",
    "    \n",
    "    reduced_inputs = []\n",
    "    for comp_id in range(len(net_config.comp_names)):\n",
    "        comp_name = net_config.comp_names[comp_id]\n",
    "        n_comp_features = len(input_cell_external_branches) + len(net_config.comp_branches[comp_id])\n",
    "        input_layer_comp = Input(name=\"input_{}_{}\".format(loc, comp_name),\n",
    "                                 shape=(1, 1, n_comp_features))\n",
    "        input_layers.append(input_layer_comp)\n",
    "        comp_net_setup.RecalcLayerSizes(n_comp_features, 2, 1)\n",
    "        reduced_comp = reduce_n_features_2d(input_layer_comp, comp_net_setup, \"{}_{}\".format(loc, comp_name))\n",
    "        reduced_inputs.append(reduced_comp)\n",
    "\n",
    "    cell_output_size = 64\n",
    "    if len(net_config.comp_names) > 1:\n",
    "        conv_all_start = Concatenate(name=\"{}_cell_concat\".format(loc), axis=3)(reduced_inputs)\n",
    "        comp_net_setup.first_layer_size = conv_all_start.shape.as_list()[3]\n",
    "        comp_net_setup.last_layer_size = 64\n",
    "        prev_layer = reduce_n_features_2d(conv_all_start, comp_net_setup, \"{}_all\".format(loc))\n",
    "    else:\n",
    "        prev_layer = reduced_inputs[0]\n",
    "        \n",
    "    model = Model(input_layers, prev_layer, name=\"DeepTau2017v2\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Kes/Library/Python/3.6/lib/python/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/Kes/Library/Python/3.6/lib/python/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_inner_egamma (InputLayer) (None, 1, 1, 86)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_inner_muon (InputLayer)   (None, 1, 1, 64)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_inner_hadrons (InputLayer (None, 1, 1, 38)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_conv_1 (Conv2D)    (None, 1, 1, 207)    18009       input_inner_egamma[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_conv_1 (Conv2D)      (None, 1, 1, 154)    10010       input_inner_muon[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_conv_1 (Conv2D)   (None, 1, 1, 92)     3588        input_inner_hadrons[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_norm_1 (BatchNorma (None, 1, 1, 207)    828         inner_egamma_conv_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_norm_1 (BatchNormali (None, 1, 1, 154)    616         inner_muon_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_norm_1 (BatchNorm (None, 1, 1, 92)     368         inner_hadrons_conv_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_activation_1 (PReL (None, 1, 1, 207)    207         inner_egamma_norm_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_activation_1 (PReLU) (None, 1, 1, 154)    154         inner_muon_norm_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_activation_1 (PRe (None, 1, 1, 92)     92          inner_hadrons_norm_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_dropout_1 (Dropout (None, 1, 1, 207)    0           inner_egamma_activation_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_dropout_1 (Dropout)  (None, 1, 1, 154)    0           inner_muon_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_dropout_1 (Dropou (None, 1, 1, 92)     0           inner_hadrons_activation_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_conv_2 (Conv2D)    (None, 1, 1, 129)    26832       inner_egamma_dropout_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_conv_2 (Conv2D)      (None, 1, 1, 96)     14880       inner_muon_dropout_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_conv_2 (Conv2D)   (None, 1, 1, 57)     5301        inner_hadrons_dropout_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_norm_2 (BatchNorma (None, 1, 1, 129)    516         inner_egamma_conv_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_norm_2 (BatchNormali (None, 1, 1, 96)     384         inner_muon_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_norm_2 (BatchNorm (None, 1, 1, 57)     228         inner_hadrons_conv_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_activation_2 (PReL (None, 1, 1, 129)    129         inner_egamma_norm_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_activation_2 (PReLU) (None, 1, 1, 96)     96          inner_muon_norm_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_activation_2 (PRe (None, 1, 1, 57)     57          inner_hadrons_norm_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_dropout_2 (Dropout (None, 1, 1, 129)    0           inner_egamma_activation_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_dropout_2 (Dropout)  (None, 1, 1, 96)     0           inner_muon_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_dropout_2 (Dropou (None, 1, 1, 57)     0           inner_hadrons_activation_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_conv_3 (Conv2D)    (None, 1, 1, 104)    13520       inner_egamma_dropout_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_conv_3 (Conv2D)      (None, 1, 1, 77)     7469        inner_muon_dropout_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_conv_3 (Conv2D)   (None, 1, 1, 46)     2668        inner_hadrons_dropout_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_norm_3 (BatchNorma (None, 1, 1, 104)    416         inner_egamma_conv_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_norm_3 (BatchNormali (None, 1, 1, 77)     308         inner_muon_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_norm_3 (BatchNorm (None, 1, 1, 46)     184         inner_hadrons_conv_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_activation_3 (PReL (None, 1, 1, 104)    104         inner_egamma_norm_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_activation_3 (PReLU) (None, 1, 1, 77)     77          inner_muon_norm_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_activation_3 (PRe (None, 1, 1, 46)     46          inner_hadrons_norm_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_egamma_dropout_3 (Dropout (None, 1, 1, 104)    0           inner_egamma_activation_3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "inner_muon_dropout_3 (Dropout)  (None, 1, 1, 77)     0           inner_muon_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inner_hadrons_dropout_3 (Dropou (None, 1, 1, 46)     0           inner_hadrons_activation_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "inner_cell_concat (Concatenate) (None, 1, 1, 227)    0           inner_egamma_dropout_3[0][0]     \n",
      "                                                                 inner_muon_dropout_3[0][0]       \n",
      "                                                                 inner_hadrons_dropout_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_conv_1 (Conv2D)       (None, 1, 1, 227)    51756       inner_cell_concat[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_norm_1 (BatchNormaliz (None, 1, 1, 227)    908         inner_all_conv_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_activation_1 (PReLU)  (None, 1, 1, 227)    227         inner_all_norm_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_dropout_1 (Dropout)   (None, 1, 1, 227)    0           inner_all_activation_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_conv_2 (Conv2D)       (None, 1, 1, 141)    32148       inner_all_dropout_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_norm_2 (BatchNormaliz (None, 1, 1, 141)    564         inner_all_conv_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_activation_2 (PReLU)  (None, 1, 1, 141)    141         inner_all_norm_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_dropout_2 (Dropout)   (None, 1, 1, 141)    0           inner_all_activation_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_conv_3 (Conv2D)       (None, 1, 1, 88)     12496       inner_all_dropout_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_norm_3 (BatchNormaliz (None, 1, 1, 88)     352         inner_all_conv_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_activation_3 (PReLU)  (None, 1, 1, 88)     88          inner_all_norm_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_dropout_3 (Dropout)   (None, 1, 1, 88)     0           inner_all_activation_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_conv_4 (Conv2D)       (None, 1, 1, 64)     5696        inner_all_dropout_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_norm_4 (BatchNormaliz (None, 1, 1, 64)     256         inner_all_conv_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_activation_4 (PReLU)  (None, 1, 1, 64)     64          inner_all_norm_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_dropout_4 (Dropout)   (None, 1, 1, 64)     0           inner_all_activation_4[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 211,783\n",
      "Trainable params: 208,819\n",
      "Non-trainable params: 2,964\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = \"DeepTau2017v2p6\"\n",
    "inner_model = create_cell_model(netConf_full, 'inner')\n",
    "inner_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SetZeros(model):\n",
    "    for layer in model.layers:\n",
    "        weight_list = layer.get_weights()\n",
    "        zero_weight_list = []\n",
    "        for weights in weight_list:\n",
    "            zero_weights = np.zeros(weights.shape)\n",
    "            zero_weight_list.append(zero_weights)\n",
    "        layer.set_weights(zero_weight_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SetZeros(inner_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_model.save('../../../../output/networks/2017v2p6/DeepTau2017v2p6_step1_e6_inner_zero.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_outer_egamma (InputLayer) (None, 1, 1, 86)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_outer_muon (InputLayer)   (None, 1, 1, 64)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_outer_hadrons (InputLayer (None, 1, 1, 38)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_conv_1 (Conv2D)    (None, 1, 1, 207)    18009       input_outer_egamma[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_conv_1 (Conv2D)      (None, 1, 1, 154)    10010       input_outer_muon[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_conv_1 (Conv2D)   (None, 1, 1, 92)     3588        input_outer_hadrons[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_norm_1 (BatchNorma (None, 1, 1, 207)    828         outer_egamma_conv_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_norm_1 (BatchNormali (None, 1, 1, 154)    616         outer_muon_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_norm_1 (BatchNorm (None, 1, 1, 92)     368         outer_hadrons_conv_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_activation_1 (PReL (None, 1, 1, 207)    207         outer_egamma_norm_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_activation_1 (PReLU) (None, 1, 1, 154)    154         outer_muon_norm_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_activation_1 (PRe (None, 1, 1, 92)     92          outer_hadrons_norm_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_dropout_1 (Dropout (None, 1, 1, 207)    0           outer_egamma_activation_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_dropout_1 (Dropout)  (None, 1, 1, 154)    0           outer_muon_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_dropout_1 (Dropou (None, 1, 1, 92)     0           outer_hadrons_activation_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_conv_2 (Conv2D)    (None, 1, 1, 129)    26832       outer_egamma_dropout_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_conv_2 (Conv2D)      (None, 1, 1, 96)     14880       outer_muon_dropout_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_conv_2 (Conv2D)   (None, 1, 1, 57)     5301        outer_hadrons_dropout_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_norm_2 (BatchNorma (None, 1, 1, 129)    516         outer_egamma_conv_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_norm_2 (BatchNormali (None, 1, 1, 96)     384         outer_muon_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_norm_2 (BatchNorm (None, 1, 1, 57)     228         outer_hadrons_conv_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_activation_2 (PReL (None, 1, 1, 129)    129         outer_egamma_norm_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_activation_2 (PReLU) (None, 1, 1, 96)     96          outer_muon_norm_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_activation_2 (PRe (None, 1, 1, 57)     57          outer_hadrons_norm_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_dropout_2 (Dropout (None, 1, 1, 129)    0           outer_egamma_activation_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_dropout_2 (Dropout)  (None, 1, 1, 96)     0           outer_muon_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_dropout_2 (Dropou (None, 1, 1, 57)     0           outer_hadrons_activation_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_conv_3 (Conv2D)    (None, 1, 1, 104)    13520       outer_egamma_dropout_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_conv_3 (Conv2D)      (None, 1, 1, 77)     7469        outer_muon_dropout_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_conv_3 (Conv2D)   (None, 1, 1, 46)     2668        outer_hadrons_dropout_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_norm_3 (BatchNorma (None, 1, 1, 104)    416         outer_egamma_conv_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_norm_3 (BatchNormali (None, 1, 1, 77)     308         outer_muon_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_norm_3 (BatchNorm (None, 1, 1, 46)     184         outer_hadrons_conv_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_activation_3 (PReL (None, 1, 1, 104)    104         outer_egamma_norm_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_activation_3 (PReLU) (None, 1, 1, 77)     77          outer_muon_norm_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_activation_3 (PRe (None, 1, 1, 46)     46          outer_hadrons_norm_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_egamma_dropout_3 (Dropout (None, 1, 1, 104)    0           outer_egamma_activation_3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "outer_muon_dropout_3 (Dropout)  (None, 1, 1, 77)     0           outer_muon_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_hadrons_dropout_3 (Dropou (None, 1, 1, 46)     0           outer_hadrons_activation_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "outer_cell_concat (Concatenate) (None, 1, 1, 227)    0           outer_egamma_dropout_3[0][0]     \n",
      "                                                                 outer_muon_dropout_3[0][0]       \n",
      "                                                                 outer_hadrons_dropout_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_conv_1 (Conv2D)       (None, 1, 1, 227)    51756       outer_cell_concat[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_norm_1 (BatchNormaliz (None, 1, 1, 227)    908         outer_all_conv_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_activation_1 (PReLU)  (None, 1, 1, 227)    227         outer_all_norm_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_dropout_1 (Dropout)   (None, 1, 1, 227)    0           outer_all_activation_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_conv_2 (Conv2D)       (None, 1, 1, 141)    32148       outer_all_dropout_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_norm_2 (BatchNormaliz (None, 1, 1, 141)    564         outer_all_conv_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_activation_2 (PReLU)  (None, 1, 1, 141)    141         outer_all_norm_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_dropout_2 (Dropout)   (None, 1, 1, 141)    0           outer_all_activation_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_conv_3 (Conv2D)       (None, 1, 1, 88)     12496       outer_all_dropout_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_norm_3 (BatchNormaliz (None, 1, 1, 88)     352         outer_all_conv_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_activation_3 (PReLU)  (None, 1, 1, 88)     88          outer_all_norm_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_dropout_3 (Dropout)   (None, 1, 1, 88)     0           outer_all_activation_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_conv_4 (Conv2D)       (None, 1, 1, 64)     5696        outer_all_dropout_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_norm_4 (BatchNormaliz (None, 1, 1, 64)     256         outer_all_conv_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_activation_4 (PReLU)  (None, 1, 1, 64)     64          outer_all_norm_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_dropout_4 (Dropout)   (None, 1, 1, 64)     0           outer_all_activation_4[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 211,783\n",
      "Trainable params: 208,819\n",
      "Non-trainable params: 2,964\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = \"DeepTau2017v2p6\"\n",
    "outer_model = create_cell_model(netConf_full, 'outer')\n",
    "outer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "SetZeros(outer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_model.save('../../../../output/networks/2017v2p6/DeepTau2017v2p6_step1_e6_outer_zero.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_core_model(net_config):\n",
    "    tau_net_setup = NetSetup('PReLU', None, 0.2, 128, 128, 1.4, None, False)\n",
    "    comp_net_setup = NetSetup('PReLU', [1, 2], 0.2, 1024, 64, 1.6, None, False)\n",
    "    dense_net_setup = NetSetup('PReLU', None, 0.2, 200, 64, 1.4, None, False)\n",
    "            \n",
    "    input_layers = []\n",
    "    high_level_features = []\n",
    "\n",
    "    if len(net_config.tau_branches) > 0:\n",
    "        input_layer_tau = Input(name=\"input_tau\", shape=(len(net_config.tau_branches),))\n",
    "        input_layers.append(input_layer_tau)\n",
    "        tau_net_setup.RecalcLayerSizes(len(net_config.tau_branches), 2, 1)\n",
    "        processed_tau = reduce_n_features_1d(input_layer_tau, tau_net_setup, 'tau')\n",
    "        #processed_tau = dense_block_sequence(input_layer_tau, tau_net_setup, 4, 'tau')\n",
    "        high_level_features.append(processed_tau)\n",
    "    \n",
    "    for loc in net_config.cell_locations:\n",
    "        cell_output_size = 64\n",
    "        input_layer_loc = Input(name=\"input_{}\".format(loc),\n",
    "                                shape=(n_cells_eta[loc], n_cells_phi[loc], cell_output_size))\n",
    "        input_layers.append(input_layer_loc)\n",
    "        prev_layer = input_layer_loc\n",
    "        \n",
    "        window_size = 3\n",
    "        current_size = n_cells_eta[loc]\n",
    "        n = 1\n",
    "        while current_size > 1:\n",
    "            win_size = min(current_size, window_size)\n",
    "            prev_layer = conv_block(prev_layer, cell_output_size, (win_size, win_size), comp_net_setup,\n",
    "                                    \"{}_all_{}x{}\".format(loc, win_size, win_size), n)\n",
    "            n += 1\n",
    "            current_size -= window_size - 1\n",
    "            \n",
    "        cells_flatten = Flatten(name=\"{}_cells_flatten\".format(loc))(prev_layer)\n",
    "        high_level_features.append(cells_flatten)\n",
    "        \n",
    "    if len(high_level_features) > 1:\n",
    "        features_concat = Concatenate(name=\"features_concat\", axis=1)(high_level_features)\n",
    "    else:\n",
    "        features_concat = high_level_features[0]\n",
    "    if net_config.final:\n",
    "        final_dense = dense_block_sequence(features_concat, dense_net_setup, 4, 'final')\n",
    "        output_layer = Dense(n_outputs, name=\"final_dense_last\",\n",
    "                             kernel_initializer=dense_net_setup.kernel_init)(final_dense)\n",
    "\n",
    "    else:\n",
    "        final_dense = dense_block(features_concat, 1024, dense_net_setup,\n",
    "                                  'tmp_{}'.format(net_config.name), 1)\n",
    "        output_layer = Dense(n_outputs, name=\"tmp_{}_dense_last\".format(net_config.name),\n",
    "                             kernel_initializer=dense_net_setup.kernel_init)(final_dense)\n",
    "    softmax_output = Activation(\"softmax\", name=\"main_output\")(output_layer)\n",
    "    \n",
    "    print(input_layers)\n",
    "    model = Model(input_layers, softmax_output, name=\"DeepTau2017v2\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'input_tau:0' shape=(?, 47) dtype=float32>, <tf.Tensor 'input_inner:0' shape=(?, 11, 11, 64) dtype=float32>, <tf.Tensor 'input_outer:0' shape=(?, 21, 21, 64) dtype=float32>]\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_outer (InputLayer)        (None, 21, 21, 64)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_conv_1 (Conv2D)   (None, 19, 19, 64)   36928       input_outer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_norm_1 (BatchNorm (None, 19, 19, 64)   256         outer_all_3x3_conv_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_activation_1 (PRe (None, 19, 19, 64)   64          outer_all_3x3_norm_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_dropout_1 (Dropou (None, 19, 19, 64)   0           outer_all_3x3_activation_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_conv_2 (Conv2D)   (None, 17, 17, 64)   36928       outer_all_3x3_dropout_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_norm_2 (BatchNorm (None, 17, 17, 64)   256         outer_all_3x3_conv_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_activation_2 (PRe (None, 17, 17, 64)   64          outer_all_3x3_norm_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_dropout_2 (Dropou (None, 17, 17, 64)   0           outer_all_3x3_activation_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_conv_3 (Conv2D)   (None, 15, 15, 64)   36928       outer_all_3x3_dropout_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_norm_3 (BatchNorm (None, 15, 15, 64)   256         outer_all_3x3_conv_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_activation_3 (PRe (None, 15, 15, 64)   64          outer_all_3x3_norm_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_dropout_3 (Dropou (None, 15, 15, 64)   0           outer_all_3x3_activation_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_conv_4 (Conv2D)   (None, 13, 13, 64)   36928       outer_all_3x3_dropout_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_norm_4 (BatchNorm (None, 13, 13, 64)   256         outer_all_3x3_conv_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_activation_4 (PRe (None, 13, 13, 64)   64          outer_all_3x3_norm_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_dropout_4 (Dropou (None, 13, 13, 64)   0           outer_all_3x3_activation_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_conv_5 (Conv2D)   (None, 11, 11, 64)   36928       outer_all_3x3_dropout_4[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_norm_5 (BatchNorm (None, 11, 11, 64)   256         outer_all_3x3_conv_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_activation_5 (PRe (None, 11, 11, 64)   64          outer_all_3x3_norm_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "input_inner (InputLayer)        (None, 11, 11, 64)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_dropout_5 (Dropou (None, 11, 11, 64)   0           outer_all_3x3_activation_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_conv_1 (Conv2D)   (None, 9, 9, 64)     36928       input_inner[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_conv_6 (Conv2D)   (None, 9, 9, 64)     36928       outer_all_3x3_dropout_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_norm_1 (BatchNorm (None, 9, 9, 64)     256         inner_all_3x3_conv_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_norm_6 (BatchNorm (None, 9, 9, 64)     256         outer_all_3x3_conv_6[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_activation_1 (PRe (None, 9, 9, 64)     64          inner_all_3x3_norm_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_activation_6 (PRe (None, 9, 9, 64)     64          outer_all_3x3_norm_6[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_dropout_1 (Dropou (None, 9, 9, 64)     0           inner_all_3x3_activation_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_dropout_6 (Dropou (None, 9, 9, 64)     0           outer_all_3x3_activation_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_conv_2 (Conv2D)   (None, 7, 7, 64)     36928       inner_all_3x3_dropout_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_conv_7 (Conv2D)   (None, 7, 7, 64)     36928       outer_all_3x3_dropout_6[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_norm_2 (BatchNorm (None, 7, 7, 64)     256         inner_all_3x3_conv_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_norm_7 (BatchNorm (None, 7, 7, 64)     256         outer_all_3x3_conv_7[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_activation_2 (PRe (None, 7, 7, 64)     64          inner_all_3x3_norm_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_activation_7 (PRe (None, 7, 7, 64)     64          outer_all_3x3_norm_7[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_dropout_2 (Dropou (None, 7, 7, 64)     0           inner_all_3x3_activation_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_dropout_7 (Dropou (None, 7, 7, 64)     0           outer_all_3x3_activation_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "input_tau (InputLayer)          (None, 47)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_conv_3 (Conv2D)   (None, 5, 5, 64)     36928       inner_all_3x3_dropout_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_conv_8 (Conv2D)   (None, 5, 5, 64)     36928       outer_all_3x3_dropout_7[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tau_dense_1 (Dense)             (None, 113)          5424        input_tau[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_norm_3 (BatchNorm (None, 5, 5, 64)     256         inner_all_3x3_conv_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_norm_8 (BatchNorm (None, 5, 5, 64)     256         outer_all_3x3_conv_8[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tau_norm_1 (BatchNormalization) (None, 113)          452         tau_dense_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_activation_3 (PRe (None, 5, 5, 64)     64          inner_all_3x3_norm_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_activation_8 (PRe (None, 5, 5, 64)     64          outer_all_3x3_norm_8[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tau_activation_1 (PReLU)        (None, 113)          113         tau_norm_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_dropout_3 (Dropou (None, 5, 5, 64)     0           inner_all_3x3_activation_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_dropout_8 (Dropou (None, 5, 5, 64)     0           outer_all_3x3_activation_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tau_dropout_1 (Dropout)         (None, 113)          0           tau_activation_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_conv_4 (Conv2D)   (None, 3, 3, 64)     36928       inner_all_3x3_dropout_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_conv_9 (Conv2D)   (None, 3, 3, 64)     36928       outer_all_3x3_dropout_8[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tau_dense_2 (Dense)             (None, 80)           9120        tau_dropout_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_norm_4 (BatchNorm (None, 3, 3, 64)     256         inner_all_3x3_conv_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_norm_9 (BatchNorm (None, 3, 3, 64)     256         outer_all_3x3_conv_9[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tau_norm_2 (BatchNormalization) (None, 80)           320         tau_dense_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_activation_4 (PRe (None, 3, 3, 64)     64          inner_all_3x3_norm_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_activation_9 (PRe (None, 3, 3, 64)     64          outer_all_3x3_norm_9[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tau_activation_2 (PReLU)        (None, 80)           80          tau_norm_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_dropout_4 (Dropou (None, 3, 3, 64)     0           inner_all_3x3_activation_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_dropout_9 (Dropou (None, 3, 3, 64)     0           outer_all_3x3_activation_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tau_dropout_2 (Dropout)         (None, 80)           0           tau_activation_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_conv_5 (Conv2D)   (None, 1, 1, 64)     36928       inner_all_3x3_dropout_4[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_conv_10 (Conv2D)  (None, 1, 1, 64)     36928       outer_all_3x3_dropout_9[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tau_dense_3 (Dense)             (None, 57)           4617        tau_dropout_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_norm_5 (BatchNorm (None, 1, 1, 64)     256         inner_all_3x3_conv_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_norm_10 (BatchNor (None, 1, 1, 64)     256         outer_all_3x3_conv_10[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tau_norm_3 (BatchNormalization) (None, 57)           228         tau_dense_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_activation_5 (PRe (None, 1, 1, 64)     64          inner_all_3x3_norm_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_activation_10 (PR (None, 1, 1, 64)     64          outer_all_3x3_norm_10[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tau_activation_3 (PReLU)        (None, 57)           57          tau_norm_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "inner_all_3x3_dropout_5 (Dropou (None, 1, 1, 64)     0           inner_all_3x3_activation_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "outer_all_3x3_dropout_10 (Dropo (None, 1, 1, 64)     0           outer_all_3x3_activation_10[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tau_dropout_3 (Dropout)         (None, 57)           0           tau_activation_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inner_cells_flatten (Flatten)   (None, 64)           0           inner_all_3x3_dropout_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "outer_cells_flatten (Flatten)   (None, 64)           0           outer_all_3x3_dropout_10[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "features_concat (Concatenate)   (None, 185)          0           tau_dropout_3[0][0]              \n",
      "                                                                 inner_cells_flatten[0][0]        \n",
      "                                                                 outer_cells_flatten[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "final_dense_1 (Dense)           (None, 200)          37200       features_concat[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "final_norm_1 (BatchNormalizatio (None, 200)          800         final_dense_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "final_activation_1 (PReLU)      (None, 200)          200         final_norm_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "final_dropout_1 (Dropout)       (None, 200)          0           final_activation_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "final_dense_2 (Dense)           (None, 200)          40200       final_dropout_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "final_norm_2 (BatchNormalizatio (None, 200)          800         final_dense_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "final_activation_2 (PReLU)      (None, 200)          200         final_norm_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "final_dropout_2 (Dropout)       (None, 200)          0           final_activation_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "final_dense_3 (Dense)           (None, 200)          40200       final_dropout_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "final_norm_3 (BatchNormalizatio (None, 200)          800         final_dense_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "final_activation_3 (PReLU)      (None, 200)          200         final_norm_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "final_dropout_3 (Dropout)       (None, 200)          0           final_activation_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "final_dense_4 (Dense)           (None, 200)          40200       final_dropout_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "final_norm_4 (BatchNormalizatio (None, 200)          800         final_dense_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "final_activation_4 (PReLU)      (None, 200)          200         final_norm_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "final_dropout_4 (Dropout)       (None, 200)          0           final_activation_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "final_dense_last (Dense)        (None, 4)            804         final_dropout_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Activation)        (None, 4)            0           final_dense_last[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 741,735\n",
      "Trainable params: 737,715\n",
      "Non-trainable params: 4,020\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = \"DeepTau2017v2p6\"\n",
    "core_model = create_core_model(netConf_full)\n",
    "core_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "SetZeros(core_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_model.save('../../../../output/networks/2017v2p6/DeepTau2017v2p6_step1_e6_core_zero.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conv_model(net_config, loc):\n",
    "    comp_net_setup = NetSetup('PReLU', [1, 2], 0.2, 1024, 64, 1.6, None, False)\n",
    "            \n",
    "    input_layers = []\n",
    "    high_level_features = []\n",
    "\n",
    "    \n",
    "    cell_output_size = 64\n",
    "    input_layer_loc = Input(name=\"input_{}\".format(loc),\n",
    "                            shape=(n_cells_eta[loc], n_cells_phi[loc], cell_output_size))\n",
    "    input_layers.append(input_layer_loc)\n",
    "    prev_layer = input_layer_loc\n",
    "\n",
    "    window_size = 3\n",
    "    current_size = n_cells_eta[loc]\n",
    "    n = 1\n",
    "    while current_size > 1:\n",
    "        win_size = min(current_size, window_size)\n",
    "        prev_layer = conv_block(prev_layer, cell_output_size, (win_size, win_size), comp_net_setup,\n",
    "                                \"{}_all_{}x{}\".format(loc, win_size, win_size), n)\n",
    "        n += 1\n",
    "        current_size -= window_size - 1\n",
    "\n",
    "    cells_flatten = Flatten(name=\"{}_cells_flatten\".format(loc))(prev_layer)\n",
    "    model = Model(input_layers, cells_flatten, name=\"DeepTau2017v2\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_inner (InputLayer)     (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "inner_all_3x3_conv_1 (Conv2D (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "inner_all_3x3_norm_1 (BatchN (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "inner_all_3x3_activation_1 ( (None, 9, 9, 64)          64        \n",
      "_________________________________________________________________\n",
      "inner_all_3x3_dropout_1 (Dro (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "inner_all_3x3_conv_2 (Conv2D (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "inner_all_3x3_norm_2 (BatchN (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "inner_all_3x3_activation_2 ( (None, 7, 7, 64)          64        \n",
      "_________________________________________________________________\n",
      "inner_all_3x3_dropout_2 (Dro (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "inner_all_3x3_conv_3 (Conv2D (None, 5, 5, 64)          36928     \n",
      "_________________________________________________________________\n",
      "inner_all_3x3_norm_3 (BatchN (None, 5, 5, 64)          256       \n",
      "_________________________________________________________________\n",
      "inner_all_3x3_activation_3 ( (None, 5, 5, 64)          64        \n",
      "_________________________________________________________________\n",
      "inner_all_3x3_dropout_3 (Dro (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "inner_all_3x3_conv_4 (Conv2D (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "inner_all_3x3_norm_4 (BatchN (None, 3, 3, 64)          256       \n",
      "_________________________________________________________________\n",
      "inner_all_3x3_activation_4 ( (None, 3, 3, 64)          64        \n",
      "_________________________________________________________________\n",
      "inner_all_3x3_dropout_4 (Dro (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "inner_all_3x3_conv_5 (Conv2D (None, 1, 1, 64)          36928     \n",
      "_________________________________________________________________\n",
      "inner_all_3x3_norm_5 (BatchN (None, 1, 1, 64)          256       \n",
      "_________________________________________________________________\n",
      "inner_all_3x3_activation_5 ( (None, 1, 1, 64)          64        \n",
      "_________________________________________________________________\n",
      "inner_all_3x3_dropout_5 (Dro (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "inner_cells_flatten (Flatten (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 186,240\n",
      "Trainable params: 185,600\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = \"DeepTau2017v2p6\"\n",
    "inner_conv_model = create_conv_model(netConf_full, 'inner')\n",
    "inner_conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_outer (InputLayer)     (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_conv_1 (Conv2D (None, 19, 19, 64)        36928     \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_norm_1 (BatchN (None, 19, 19, 64)        256       \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_activation_1 ( (None, 19, 19, 64)        64        \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_dropout_1 (Dro (None, 19, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_conv_2 (Conv2D (None, 17, 17, 64)        36928     \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_norm_2 (BatchN (None, 17, 17, 64)        256       \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_activation_2 ( (None, 17, 17, 64)        64        \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_dropout_2 (Dro (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_conv_3 (Conv2D (None, 15, 15, 64)        36928     \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_norm_3 (BatchN (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_activation_3 ( (None, 15, 15, 64)        64        \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_dropout_3 (Dro (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_conv_4 (Conv2D (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_norm_4 (BatchN (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_activation_4 ( (None, 13, 13, 64)        64        \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_dropout_4 (Dro (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_conv_5 (Conv2D (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_norm_5 (BatchN (None, 11, 11, 64)        256       \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_activation_5 ( (None, 11, 11, 64)        64        \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_dropout_5 (Dro (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_conv_6 (Conv2D (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_norm_6 (BatchN (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_activation_6 ( (None, 9, 9, 64)          64        \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_dropout_6 (Dro (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_conv_7 (Conv2D (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_norm_7 (BatchN (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_activation_7 ( (None, 7, 7, 64)          64        \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_dropout_7 (Dro (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_conv_8 (Conv2D (None, 5, 5, 64)          36928     \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_norm_8 (BatchN (None, 5, 5, 64)          256       \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_activation_8 ( (None, 5, 5, 64)          64        \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_dropout_8 (Dro (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_conv_9 (Conv2D (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_norm_9 (BatchN (None, 3, 3, 64)          256       \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_activation_9 ( (None, 3, 3, 64)          64        \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_dropout_9 (Dro (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_conv_10 (Conv2 (None, 1, 1, 64)          36928     \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_norm_10 (Batch (None, 1, 1, 64)          256       \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_activation_10  (None, 1, 1, 64)          64        \n",
      "_________________________________________________________________\n",
      "outer_all_3x3_dropout_10 (Dr (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "outer_cells_flatten (Flatten (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 372,480\n",
      "Trainable params: 371,200\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = \"DeepTau2017v2p6\"\n",
    "outer_conv_model = create_conv_model(netConf_full, 'outer')\n",
    "outer_conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
